{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SET WORKING DIR\n",
    "# Any 'sar.txt' files in this dir will be processed\n",
    "#dir = r'/mnt/nvme_nfs_share/AIBench_shared_disk/Scenario/performance/pods/perf-nineteen-0-6fbf77596d-ththg/sar-4_14_localsave'\n",
    "\n",
    "sar_list1 = [\n",
    "    {'name': 'kafka-broker', 'dir': '/mnt/nvme_nfs_share/AIBench_shared_disk/Scenario/dummy/aibench-20190506184740525004/dummy-0-557689c859-t2nw8/perf-fmx123-0-cd4b4877c-bj8tp/sar-06052019185157'},\n",
    "    {'name': 'kafka-broker', 'dir': '/mnt/nvme_nfs_share/AIBench_shared_disk/Scenario/dummy/aibench-20190508102117526598/dummy-0-557689c859-zshj8/perf-fmx123-0-cd4b4877c-nsl2h/sar-08052019102507'},\n",
    "    {'name': 'kafka-broker', 'dir': '/mnt/nvme_nfs_share/AIBench_shared_disk/Scenario/dummy/aibench-20190508103214820439/dummy-0-557689c859-z6gtk/perf-fmx123-0-cd4b4877c-nsl2h/sar-08052019103234'},\n",
    "    {'name': 'kafka-broker', 'dir': '/mnt/nvme_nfs_share/AIBench_shared_disk/Scenario/dummy/aibench-20190508103344507186/dummy-0-557689c859-6plqb/perf-fmx123-0-cd4b4877c-nsl2h/sar-08052019103400'},\n",
    "    {'name': 'kafka-broker', 'dir': '/mnt/nvme_nfs_share/AIBench_shared_disk/Scenario/dummy/aibench-20190508103835204358/dummy-0-557689c859-cps5c/perf-fmx123-0-cd4b4877c-nsl2h/sar-08052019103849'},\n",
    "    {'name': 'kafka-broker', 'dir': '/mnt/nvme_nfs_share/AIBench_shared_disk/Scenario/dummy/aibench-20190508114752682806/dummy-0-557689c859-hkpsl/perf-fmx123-0-cd4b4877c-xczvf/sar-08052019115123'},\n",
    "    {'name': 'kafka-broker', 'dir': '/mnt/nvme_nfs_share/AIBench_shared_disk/Scenario/dummy/aibench-20190508115312008026/dummy-0-557689c859-nc6b7/perf-fmx123-0-cd4b4877c-lbq95/sar-08052019115627'},\n",
    "]\n",
    "\n",
    "sar_list2 = [\n",
    "    {'name': 'kafka-broker',      'dir': '/mnt/nvme_nfs_share/AIBench_shared_disk/Scenario/kafka-benchmark/aibench-20190529110121067216/e2e-kafkabroker-configsar-0-9786f6b65-np68c/perf-fmx055-0-8cd5fc48c-rwqrr/sar-29052019110230'},\n",
    "    {'name': 'kafka-broker-one',  'dir': '/mnt/nvme_nfs_share/AIBench_shared_disk/Scenario/kafka-benchmark/aibench-20190529110121067216/e2e-kafkabroker-one-configsar-0-77dc5dc4b5-f52w2/perf-fmx098-0-579cc784cf-296nb/sar-29052019110226'},\n",
    "    {'name': 'kafka-broker-two',  'dir': '/mnt/nvme_nfs_share/AIBench_shared_disk/Scenario/kafka-benchmark/aibench-20190529110121067216/e2e-kafkabroker-two-configsar-0-7fb5df7c9f-v6xmt/perf-fmx036-0-c64bd69df-4t2vh/sar-29052019110226'},\n",
    "    {'name': 'kafka-consumer-01', 'dir': '/mnt/nvme_nfs_share/AIBench_shared_disk/Scenario/kafka-benchmark/aibench-20190529110121067216/kafka-benchmark-consumer-01-configsar-0-55dbf9b6d5-mj47r/perf-fmx124-0-55b7cbd864-vdwth/sar-29052019110225'},\n",
    "    {'name': 'kafka-consumer',    'dir': '/mnt/nvme_nfs_share/AIBench_shared_disk/Scenario/kafka-benchmark/aibench-20190529110121067216/kafka-benchmark-consumer-configsar-0-6949455d86-crdj5/perf-fmx118-0-dbb97b579-vvgt5/sar-29052019110225'},\n",
    "    {'name': 'kafka-producer',    'dir': '/mnt/nvme_nfs_share/AIBench_shared_disk/Scenario/kafka-benchmark/aibench-20190529110121067216/kafka-benchmark-producer-configsar-0-68d8c85c8f-f2vvb/perf-fmx120-0-6ff46d8888-kz96w/sar-29052019110230'},\n",
    "]\n",
    "\n",
    "test_list = [{'name': 'srgans', 'dir': '/mnt/nvme_nfs_share/AIBench_shared_disk/Scenario/performance/pods/perf-nineteen-0-6fbf77596d-ththg/sar-4_14_localsave'}]\n",
    "\n",
    "workload_list = test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import xlsxwriter\n",
    "from xlsxwriter.utility import xl_rowcol_to_cell\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'cursor' state for where to position chart in worksheet\n",
    "chart_position_state = {}\n",
    "\n",
    "def add_chart(workbook, chartsheet, datasheet, df, chart_type, start_row, end_row, title, y_col_names,\n",
    "              x_col_name=None, chart_subtype=None, x_label=None, y_label=None, x_log_base=None, y_log_base=None,\n",
    "              x_min=None, x_max=None, y_min=None, y_max=None, disable_legend=False, additional_series=None,\n",
    "              num_format='General', series_names=None, gap=None, x_interval_unit=None, y_interval_unit=None,\n",
    "              x_interval_tick=None, y_interval_tick=None, series_filters=None, trendline=None,\n",
    "              x_visible=True, y_visible=True, x_scale=2, y_scale=2, chart_position='below', series_creator=None):\n",
    "    \n",
    "    if workbook not in chart_position_state:\n",
    "        chart_position_state[workbook] = {}\n",
    "    if chartsheet not in chart_position_state[workbook]:\n",
    "        chart_position_state[workbook][chartsheet] = {\n",
    "            'chart_col' : 1,\n",
    "            'chart_row_right' : 1,\n",
    "            'chart_row_below' : 1,\n",
    "        }\n",
    "    \n",
    "    # check columns exist\n",
    "    columns = df.columns\n",
    "    if x_col_name is None:\n",
    "        x_col = None\n",
    "        categories = None\n",
    "    else:\n",
    "        if not x_col_name in columns:\n",
    "            #print(\"x-axis %s is not in columns: %s\"%(x_col_name, columns))\n",
    "            return False\n",
    "        x_col = columns.get_loc(x_col_name) + 1\n",
    "        categories = [datasheet, start_row, x_col, end_row, x_col]\n",
    "    for y_col_name in y_col_names: \n",
    "        if not y_col_name in columns:\n",
    "            #print(\"y-axis %s is not in columns: %s\"%(y_col_name, columns))\n",
    "            return False\n",
    "    \n",
    "    # create chart\n",
    "    chart_worksheet = workbook.get_worksheet_by_name(chartsheet)\n",
    "    chart = workbook.add_chart({'type': chart_type, 'subtype': chart_subtype})\n",
    "    chart.show_blanks_as('span')\n",
    "    \n",
    "    \n",
    "    # add main series\n",
    "    for series_idx, y_col_name in enumerate(y_col_names):\n",
    "        y_col = columns.get_loc(y_col_name) + 1\n",
    "        if series_names is not None:\n",
    "            series_name = series_names[series_idx]\n",
    "        else:\n",
    "            series_name = y_col_name\n",
    "\n",
    "        if series_filters is None and series_creator is None:\n",
    "            chart.add_series({\n",
    "                'name':       series_name,\n",
    "                'categories': categories,\n",
    "                'values':     [datasheet, start_row, y_col, end_row, y_col],\n",
    "                'gap':        gap,\n",
    "                'trendline':  trendline,\n",
    "            })\n",
    "        else:\n",
    "            if 'row' not in df.columns:\n",
    "                print('ERROR: could not find \\'row\\' column in df')\n",
    "                return False\n",
    "            \n",
    "            #find unique combinations, get row/col of each\n",
    "            if series_filters is not None:\n",
    "                filtered_df = filter_df(series_filters, df)\n",
    "            else:\n",
    "                filtered_df = df\n",
    "                \n",
    "            if series_creator is not None:\n",
    "                series_names = filtered_df[series_creator].unique()\n",
    "            else:\n",
    "                series_names = [series_name]\n",
    "\n",
    "            for series_name in series_names:\n",
    "                if series_creator is not None:\n",
    "                    series_df = filtered_df[filtered_df[series_creator] == series_name]\n",
    "                else:\n",
    "                    series_df = filtered_df\n",
    "                \n",
    "                values = '=('\n",
    "                categories = '=('\n",
    "                for row in series_df['row'].values:\n",
    "                    values += datasheet + '!' + str(xl_rowcol_to_cell(row+1, y_col)) + ','\n",
    "                    categories += datasheet + '!' + str(xl_rowcol_to_cell(row+1, x_col)) + ','\n",
    "                values = values.rstrip(',') + ')'\n",
    "                categories = categories.rstrip(',') + ')'\n",
    "\n",
    "                chart.add_series({\n",
    "                    'name':       series_name,\n",
    "                    'categories': categories,\n",
    "                    'values':     values,\n",
    "                    'gap':        gap,\n",
    "                    'trendline':  trendline,\n",
    "                })\n",
    "    \n",
    "    \n",
    "    # add additional series formatted by user\n",
    "    # Could just chart raw values but xlsxwriter prints annoying warning so instead I'll write data to sheet and chart that\n",
    "    if additional_series is not None:\n",
    "        cat_count = val_count = 0\n",
    "        for series in additional_series:\n",
    "            chart_col = chart_position_state[workbook][chartsheet]['chart_col']\n",
    "            chart_row = chart_position_state[workbook][chartsheet]['chart_row_below']\n",
    "            cat_start_cell = xl_rowcol_to_cell(chart_row + cat_count, chart_col)\n",
    "            val_start_cell = xl_rowcol_to_cell(chart_row + val_count, chart_col + 1)\n",
    "            cat_count += len(series['categories'])\n",
    "            val_count += len(series['values'])\n",
    "            cat_end_cell = xl_rowcol_to_cell(chart_row + cat_count - 1, chart_col)\n",
    "            val_end_cell = xl_rowcol_to_cell(chart_row + val_count - 1, chart_col + 1)\n",
    "            chart_worksheet.write_column(cat_start_cell, series['categories'])\n",
    "            chart_worksheet.write_column(val_start_cell, series['values'])\n",
    "            series['categories'] = chartsheet + '!' + cat_start_cell + ':' + cat_end_cell\n",
    "            series['values'] = chartsheet + '!' + val_start_cell + ':' + val_end_cell\n",
    "            chart.add_series(series)\n",
    "        \n",
    "    # title\n",
    "    chart.set_title({\n",
    "        'name': title,\n",
    "        'name_font': {'size': 18},\n",
    "    })\n",
    "    \n",
    "    # legend\n",
    "    chart.set_legend({\n",
    "        'font': {'size': 12},\n",
    "        'position': 'top',\n",
    "        'none': disable_legend,\n",
    "    })\n",
    "    \n",
    "    # axis\n",
    "    chart.set_x_axis({\n",
    "        'name': x_label,\n",
    "        'name_font': {'size': 12},\n",
    "        'num_font': {'size': 11},\n",
    "        'label_position': 'low',\n",
    "        'min': x_min,\n",
    "        'max': x_max,\n",
    "        'log_base': x_log_base,\n",
    "        'num_format': num_format,\n",
    "        'interval_unit': x_interval_unit,\n",
    "        'interval_tick': x_interval_tick,\n",
    "        'visible': x_visible,\n",
    "    })\n",
    "    chart.set_y_axis({\n",
    "        'name': y_label,\n",
    "        'name_font': {'size': 12},\n",
    "        'num_font': {'size': 11},\n",
    "        'label_position': 'low',\n",
    "        'min': y_min,\n",
    "        'max': y_max,\n",
    "        'log_base': y_log_base,\n",
    "        'num_format': num_format,\n",
    "        'interval_unit': y_interval_unit,\n",
    "        'interval_tick': y_interval_tick,\n",
    "        'visible': y_visible,\n",
    "    })\n",
    "    \n",
    "    # position & size\n",
    "    if chart_position == 'below':  # anything other than 'below' will put to right\n",
    "        chart_col = chart_position_state[workbook][chartsheet]['chart_col'] = 1  # reset column\n",
    "        chart_row = chart_position_state[workbook][chartsheet]['chart_row_below']\n",
    "    else:\n",
    "        chart_col = chart_position_state[workbook][chartsheet]['chart_col']\n",
    "        chart_row = chart_position_state[workbook][chartsheet]['chart_row_right']\n",
    "        \n",
    "    chart_worksheet.insert_chart(chart_row, chart_col, chart, {'x_scale': x_scale, 'y_scale': y_scale})\n",
    "\n",
    "    chart_position_state[workbook][chartsheet]['chart_col'] = chart_col + (8 * x_scale)  # advance column\n",
    "    chart_position_state[workbook][chartsheet]['chart_row_right'] = chart_row  # save row in case next chart is 'right'\n",
    "    chart_position_state[workbook][chartsheet]['chart_row_below'] = chart_row + (15 * y_scale)  # advance row in case next chart is 'below'\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df(filters, df):\n",
    "    filter_string = \"\"\n",
    "    for column, values in filters.items():\n",
    "        if column not in df.columns:\n",
    "            return None\n",
    "        else:\n",
    "            if values is None:  # get all of them\n",
    "                filter_vals = list(df[column].unique())\n",
    "            elif type(values) is list:  # get list\n",
    "                filter_vals = values\n",
    "            else:  # get one value\n",
    "                filter_vals = [values]\n",
    "\n",
    "            if filter_string != \"\":\n",
    "                filter_string += \" & \"\n",
    "            filter_string += \"(df['\" + str(column) + \"'].isin(\" + str(filter_vals) + \"))\"\n",
    "\n",
    "    filter_string = \"df.loc[\" + filter_string + \"]\"\n",
    "    return eval(filter_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert sar.txt to individual files\n",
    "for entry in workload_list:\n",
    "    workload = entry['name']\n",
    "    sar_dir = entry['dir']\n",
    "    file = sar_dir + '/sar.txt'\n",
    "    outfile = sar_dir + \"/\" + workload + '_sar.xlsx'\n",
    "    \n",
    "    if not os.path.isfile(file):\n",
    "        print(\"Can't find file %s\"(file))\n",
    "        continue\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"%s : %s\"%(workload, file))\n",
    "    \n",
    "    with open(file) as fp:\n",
    "        linenum = 0\n",
    "        header = False\n",
    "        filetype = None\n",
    "        cpu_cores_stat = None\n",
    "        #cpustat = None\n",
    "        memstat = None\n",
    "        netstat = None\n",
    "        iostat = None\n",
    "        for line in fp:\n",
    "            linenum += 1\n",
    "            \n",
    "            if linenum % 5000 == 0:\n",
    "                print(\"\\tProcessed %d lines...\"%(linenum))\n",
    "            \n",
    "            # line after blank is header\n",
    "            if line.isspace() or line == \"\":\n",
    "                header = True\n",
    "            else:\n",
    "                if header == True:\n",
    "                    header = False\n",
    "                    if re.search('%usr', line):\n",
    "                        filetype = \"cpu_cores_stat\"\n",
    "                        if cpu_cores_stat is None:\n",
    "                            cpu_cores_stat = pd.DataFrame()\n",
    "                            cpu_columns = line.split()\n",
    "                            cpu_columns[0] = \"Timestamp\"\n",
    "                            cpu_columns = pd.Series(cpu_columns)\n",
    "                    elif re.search('kbmemfree', line):\n",
    "                        filetype = \"memstat\"\n",
    "                        if memstat is None:\n",
    "                            memstat = pd.DataFrame()\n",
    "                            mem_columns = line.split()\n",
    "                            mem_columns[0] = \"Timestamp\"\n",
    "                            mem_columns = pd.Series(mem_columns)\n",
    "                    elif re.search('rd_sec/s', line):\n",
    "                        filetype = \"iostat\"\n",
    "                        if iostat is None:\n",
    "                            iostat = pd.DataFrame()\n",
    "                            io_columns = line.split()\n",
    "                            io_columns[0] = \"Timestamp\"\n",
    "                            io_columns = pd.Series(io_columns)\n",
    "                    elif re.search('rxpck/s', line):\n",
    "                        filetype = \"netstat\"\n",
    "                        if netstat is None:\n",
    "                            netstat = pd.DataFrame()\n",
    "                            net_columns = line.split()\n",
    "                            net_columns[0] = \"Timestamp\"\n",
    "                            net_columns = pd.Series(net_columns)\n",
    "                    else:\n",
    "                        #ignore it\n",
    "                        filetype = None\n",
    "                else:\n",
    "                    # add to dataframe\n",
    "                    if filetype == \"cpu_cores_stat\":\n",
    "                        cpu_cores_stat = cpu_cores_stat.append(pd.Series(line.split()), ignore_index=True)\n",
    "                    elif filetype == \"memstat\":\n",
    "                        memstat = memstat.append(pd.Series(line.split()), ignore_index=True)\n",
    "                    elif filetype == \"iostat\":\n",
    "                        iostat = iostat.append(pd.Series(line.split()), ignore_index=True)\n",
    "                    elif filetype == \"netstat\":\n",
    "                        netstat = netstat.append(pd.Series(line.split()), ignore_index=True)\n",
    "        \n",
    "        # set column headers\n",
    "        cpu_cores_stat.columns = cpu_columns\n",
    "        memstat.columns = mem_columns\n",
    "        iostat.columns = io_columns\n",
    "        netstat.columns = net_columns\n",
    "        \n",
    "        # create summary cpustat\n",
    "        cpustat = cpu_cores_stat[cpu_cores_stat['CPU'] == 'all']\n",
    "        cpustat = cpustat.reset_index(drop=True)\n",
    "        \n",
    "        #list of all dfs\n",
    "        result_dfs = [cpu_cores_stat, cpustat, memstat, iostat, netstat]\n",
    "        \n",
    "        # add some columns to all\n",
    "        FMT = '%H:%M:%S'\n",
    "        for df in result_dfs:\n",
    "            # convert to numeric\n",
    "            cols = df.columns.drop('Timestamp')\n",
    "            df[cols] = df[cols].apply(pd.to_numeric, errors='ignore')\n",
    "            \n",
    "            # row\n",
    "            df['row'] = list(range(len(df.index)))  # because index may not be a number\n",
    "            \n",
    "            # duration\n",
    "            df['duration'] = None\n",
    "            duration_index = df.columns.get_loc(\"duration\")\n",
    "            for index, row in df.iterrows():\n",
    "                if index+1 < len(df.index):\n",
    "                    s1 = row['Timestamp']\n",
    "                    s2 = df.iloc[index+1]['Timestamp']\n",
    "                    tdelta = datetime.strptime(s2, FMT) - datetime.strptime(s1, FMT)\n",
    "                    df.iloc[index, duration_index] = tdelta.seconds\n",
    "            df.iloc[-1, duration_index] = df.iloc[-2]['duration']  # set last interval duration\n",
    "            \n",
    "            # cumulative duration\n",
    "            df['cum_duration'] = df['duration'].cumsum()\n",
    "        \n",
    "        # add some columns to specific dfs\n",
    "        netstat['rx+txkB/s'] = netstat['rxkB/s'] + netstat['txkB/s']\n",
    "        \n",
    "        #create xlsx writer and save data\n",
    "        print(\"\\tPrinting Excel stats\")\n",
    "        writer = pd.ExcelWriter(outfile, engine='xlsxwriter')\n",
    "        workbook = writer.book\n",
    "        cpu_cores_stat.to_excel(writer, sheet_name='corestat')\n",
    "        cpustat.to_excel(writer, sheet_name='cpustat')\n",
    "        memstat.to_excel(writer, sheet_name='memstat')\n",
    "        iostat.to_excel(writer, sheet_name='iostat')\n",
    "        netstat.to_excel(writer, sheet_name='netstat')\n",
    "        \n",
    "        # create charts\n",
    "        add_chart(\n",
    "            workbook=workbook,\n",
    "            chartsheet='cpustat',\n",
    "            datasheet='cpustat',\n",
    "            df=cpustat,\n",
    "            chart_type='area',\n",
    "            chart_subtype='stacked',\n",
    "            start_row=1,\n",
    "            end_row=len(cpustat.index),\n",
    "            x_col_name='cum_duration',\n",
    "            y_col_names=[\n",
    "                '%iowait',\n",
    "                '%usr',\n",
    "                '%idle',\n",
    "                '%sys',\n",
    "            ],\n",
    "            series_names=[\n",
    "                'IO wait',\n",
    "                'User',\n",
    "                'Idle',\n",
    "                'System',\n",
    "            ],\n",
    "            title='CPU Time',\n",
    "            x_label='Time (s)',\n",
    "            y_label='% Cycles Spent',\n",
    "            y_min=0,\n",
    "            y_max=100,\n",
    "            num_format='0',\n",
    "        )\n",
    "        add_chart(\n",
    "            workbook=workbook,\n",
    "            chartsheet='memstat',\n",
    "            datasheet='memstat',\n",
    "            df=memstat,\n",
    "            chart_type='scatter',\n",
    "            chart_subtype='smooth',\n",
    "            start_row=1,\n",
    "            end_row=len(memstat.index),\n",
    "            x_col_name='cum_duration',\n",
    "            y_col_names=[\n",
    "                '%memused',\n",
    "            ],\n",
    "            series_names=[\n",
    "                'Footprint',\n",
    "            ],\n",
    "            title='DRAM Footprint',\n",
    "            x_label='Time (s)',\n",
    "            y_label='Memory Used (%)',\n",
    "            num_format='0',\n",
    "            disable_legend=True,\n",
    "        )\n",
    "        add_chart(\n",
    "            workbook=workbook,\n",
    "            chartsheet='iostat',\n",
    "            datasheet='iostat',\n",
    "            df=iostat,\n",
    "            chart_type='scatter',\n",
    "            chart_subtype='smooth',\n",
    "            start_row=1,\n",
    "            end_row=len(iostat.index),\n",
    "            x_col_name='cum_duration',\n",
    "            y_col_names=[\n",
    "                '%util',\n",
    "            ],\n",
    "            title='IO Utilization per Device',\n",
    "            x_label='Time (s)',\n",
    "            y_label='Utilization (%)',\n",
    "            num_format='0',\n",
    "            series_creator='DEV'\n",
    "        )\n",
    "        add_chart(\n",
    "            workbook=workbook,\n",
    "            chartsheet='netstat',\n",
    "            datasheet='netstat',\n",
    "            df=netstat,\n",
    "            chart_type='scatter',\n",
    "            chart_subtype='smooth',\n",
    "            start_row=1,\n",
    "            end_row=len(netstat.index),\n",
    "            x_col_name='cum_duration',\n",
    "            y_col_names=[\n",
    "                'rxkB/s',\n",
    "            ],\n",
    "            title='Network Read Bandwidth per Device',\n",
    "            x_label='Time (s)',\n",
    "            y_label='KB/s',\n",
    "            num_format='0',\n",
    "            series_creator='IFACE'\n",
    "        )\n",
    "        add_chart(\n",
    "            workbook=workbook,\n",
    "            chartsheet='netstat',\n",
    "            datasheet='netstat',\n",
    "            df=netstat,\n",
    "            chart_type='scatter',\n",
    "            chart_subtype='smooth',\n",
    "            start_row=1,\n",
    "            end_row=len(netstat.index),\n",
    "            x_col_name='cum_duration',\n",
    "            y_col_names=[\n",
    "                'txkB/s',\n",
    "            ],\n",
    "            title='Network Write Bandwidth per Device',\n",
    "            x_label='Time (s)',\n",
    "            y_label='KB/s',\n",
    "            num_format='0',\n",
    "            series_creator='IFACE'\n",
    "        )\n",
    "        add_chart(\n",
    "            workbook=workbook,\n",
    "            chartsheet='netstat',\n",
    "            datasheet='netstat',\n",
    "            df=netstat,\n",
    "            chart_type='scatter',\n",
    "            chart_subtype='smooth',\n",
    "            start_row=1,\n",
    "            end_row=len(netstat.index),\n",
    "            x_col_name='cum_duration',\n",
    "            y_col_names=[\n",
    "                'rx+txkB/s',\n",
    "            ],\n",
    "            title='Network Bandwidth per Device',\n",
    "            x_label='Time (s)',\n",
    "            y_label='KB/s',\n",
    "            num_format='0',\n",
    "            series_creator='IFACE'\n",
    "        )\n",
    "        \n",
    "        writer.save()\n",
    "        \n",
    "        #print(\"\\tPrinting cpu stats\")\n",
    "        #filename = sar_dir + \"/\" + workload + '_cpustat.csv'\n",
    "        #cpu_cores_stat.to_csv(filename)\n",
    "\n",
    "        #print(\"\\tPrinting mem stats\")\n",
    "        #filename = sar_dir + \"/\" + workload + '_memstat.csv'\n",
    "        #memstat.to_csv(filename)\n",
    "\n",
    "        #print(\"\\tPrinting io stats\")\n",
    "        #filename = sar_dir + \"/\" + workload + '_iostat.csv'\n",
    "        #iostat.to_csv(filename)\n",
    "\n",
    "        #print(\"\\tPrinting net stats\")\n",
    "        #filename = sar_dir + \"/\" + workload + '_netstat.csv'\n",
    "        #netstat.to_csv(filename)\n",
    "        \n",
    "        print(\"\\tFinished file\")\n",
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
